<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="generator" content="Hugo 0.83.1" />
  <link rel="canonical" href="https://op-y.github.io/kubeadm-ha-cluster/" />

  
    
    <meta name="description" content="目标 本篇记录使用 kubeadm 完成一个高可用 Kubernetes 集群搭建。
参考文档
 容器运行时 安装 kubernetes 高可用拓扑选项 使用 Kubeadm 创建一个高可用 etcd 集群 etcd 配置 利用 kubeadm 创建高可用集群 flannel 配置     使用的版本 Kubernetes 1.28.2   环境准备 已有集群是使用阿里云轻应用服务器作为实验环境搭建的，所以先准备一台新的集群，选用了 Ubuntu 镜像（原有节点使用的 Debian，操作验证了不同 Linux 发行版组成集群没啥问题）。
安装一些必要的软件包 apt-get update apt-get install git lrzsz tmux zsh fonts-powerline # lrzsz 用于本地终端与云主机传输小文件 # tmux 方便登录云主机操作 # zsh 替换云主机shell环境 如果喜欢bash也可以保持默认环境 # fonts-powerline 是后续使用oh-my-zsh主题需要的字体  安装 oh-my-zsh 参考官方文档 https://ohmyz.sh/#install 过程非常简单
sh -c &#34;$(curl -fsSL https://raw.">
  

  <link rel="apple-touch-icon" sizes="180x180" href="https://op-y.github.io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://op-y.github.io/favicon-32x32.png"> 
  <link rel="icon" type="image/png" sizes="16x16" href="https://op-y.github.io/favicon-16x16.png"> 
  <link rel="manifest" href="https://op-y.github.io/site.webmanifest"> 
  <link rel="mask-icon" href="https://op-y.github.io/safari-pinned-tab.svg" color="#000000"> 
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

  <style>
    body {
      visibility: hidden;
      opacity: 0;
    }
  </style>

  <style id="darkTheme">
    .intro-and-nav,
    .main-and-footer {
      filter: invert(100%);
    }

    * {
      background-color: inherit
    }

    img:not([src*=".svg"]),
    .colors,
    iframe,
    .demo-container {
      filter: invert(100%);
    }
  </style>

  <link rel="stylesheet" href="/css/prism.css" media="none" onload="this.media='all';">

  
  
  <link rel="stylesheet" type="text/css" href="/css/styles.css">

  

  
  
  <title>kubeadm实战: 搭建高可用集群 | Qin的自习室</title>
</head>

  <body>
    <a href="#main">skip to content</a>
    <noscript>
  <style>
    body {
      visibility: visible;
      opacity: 1;
    }
  </style>
</noscript>

    <svg style="display: none">
  <symbol id="bookmark" viewBox="0 0 40 50">
   <g transform="translate(2266 3206.2)">
    <path style="stroke:currentColor;stroke-width:3.2637;fill:none" d="m-2262.2-3203.4-.2331 42.195 16.319-16.318 16.318 16.318.2331-42.428z"/>
   </g>
  </symbol>

  <symbol id="w3c" viewBox="0 0 127.09899 67.763">
   <text font-size="83" style="font-size:83px;font-family:Trebuchet;letter-spacing:-12;fill-opacity:0" letter-spacing="-12" y="67.609352" x="-26.782778">W3C</text>
   <text font-size="83" style="font-size:83px;font-weight:bold;font-family:Trebuchet;fill-opacity:0" y="67.609352" x="153.21722" font-weight="bold">SVG</text>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m33.695.377 12.062 41.016 12.067-41.016h8.731l-19.968 67.386h-.831l-12.48-41.759-12.479 41.759h-.832l-19.965-67.386h8.736l12.061 41.016 8.154-27.618-3.993-13.397h8.737z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m91.355 46.132c0 6.104-1.624 11.234-4.862 15.394-3.248 4.158-7.45 6.237-12.607 6.237-3.882 0-7.263-1.238-10.148-3.702-2.885-2.47-5.02-5.812-6.406-10.022l6.82-2.829c1.001 2.552 2.317 4.562 3.953 6.028 1.636 1.469 3.56 2.207 5.781 2.207 2.329 0 4.3-1.306 5.909-3.911 1.609-2.606 2.411-5.738 2.411-9.401 0-4.049-.861-7.179-2.582-9.399-1.995-2.604-5.129-3.912-9.397-3.912h-3.327v-3.991l11.646-20.133h-14.062l-3.911 6.655h-2.493v-14.976h32.441v4.075l-12.31 21.217c4.324 1.385 7.596 3.911 9.815 7.571 2.22 3.659 3.329 7.953 3.329 12.892z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.21 0 1.414 8.6-5.008 9.583s-1.924-4.064-5.117-6.314c-2.693-1.899-4.447-2.309-7.186-1.746-3.527.73-7.516 4.938-9.258 10.13-2.084 6.21-2.104 9.218-2.178 11.978-.115 4.428.58 7.043.58 7.043s-3.04-5.626-3.011-13.866c.018-5.882.947-11.218 3.666-16.479 2.404-4.627 5.954-7.404 9.114-7.728 3.264-.343 5.848 1.229 7.841 2.938 2.089 1.788 4.213 5.698 4.213 5.698l4.94-9.837z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.82 48.674s-2.208 3.957-3.589 5.48c-1.379 1.524-3.849 4.209-6.896 5.555-3.049 1.343-4.646 1.598-7.661 1.306-3.01-.29-5.807-2.032-6.786-2.764-.979-.722-3.486-2.864-4.897-4.854-1.42-2-3.634-5.995-3.634-5.995s1.233 4.001 2.007 5.699c.442.977 1.81 3.965 3.749 6.572 1.805 2.425 5.315 6.604 10.652 7.545 5.336.945 9.002-1.449 9.907-2.031.907-.578 2.819-2.178 4.032-3.475 1.264-1.351 2.459-3.079 3.116-4.108.487-.758 1.276-2.286 1.276-2.286l-1.276-6.644z"/>
  </symbol>

  <symbol id="tag" viewBox="0 0 177.16535 177.16535">
    <g transform="translate(0 -875.2)">
     <path style="fill-rule:evenodd;stroke-width:0;fill:currentColor" d="m159.9 894.3-68.79 8.5872-75.42 77.336 61.931 60.397 75.429-76.565 6.8495-69.755zm-31.412 31.835a10.813 10.813 0 0 1 1.8443 2.247 10.813 10.813 0 0 1 -3.5174 14.872l-.0445.0275a10.813 10.813 0 0 1 -14.86 -3.5714 10.813 10.813 0 0 1 3.5563 -14.863 10.813 10.813 0 0 1 13.022 1.2884z"/>
    </g>
  </symbol>

  <symbol id="balloon" viewBox="0 0 141.73228 177.16535">
   <g transform="translate(0 -875.2)">
    <g>
     <path style="fill:currentColor" d="m68.156 882.83-.88753 1.4269c-4.9564 7.9666-6.3764 17.321-5.6731 37.378.36584 10.437 1.1246 23.51 1.6874 29.062.38895 3.8372 3.8278 32.454 4.6105 38.459 4.6694-.24176 9.2946.2879 14.377 1.481 1.2359-3.2937 5.2496-13.088 8.886-21.623 6.249-14.668 8.4128-21.264 10.253-31.252 1.2464-6.7626 1.6341-12.156 1.4204-19.764-.36325-12.93-2.1234-19.487-6.9377-25.843-2.0833-2.7507-6.9865-7.6112-7.9127-7.8436-.79716-.20019-6.6946-1.0922-6.7755-1.0248-.02213.0182-5.0006-.41858-7.5248-.22808l-2.149-.22808h-3.3738z"/>
     <path style="fill:currentColor" d="m61.915 883.28-3.2484.4497c-1.7863.24724-3.5182.53481-3.8494.63994-2.4751.33811-4.7267.86957-6.7777 1.5696-.28598 0-1.0254.20146-2.3695.58589-5.0418 1.4418-6.6374 2.2604-8.2567 4.2364-6.281 7.6657-11.457 18.43-12.932 26.891-1.4667 8.4111.71353 22.583 5.0764 32.996 3.8064 9.0852 13.569 25.149 22.801 37.517 1.3741 1.841 2.1708 2.9286 2.4712 3.5792 3.5437-1.1699 6.8496-1.9336 10.082-2.3263-1.3569-5.7831-4.6968-21.86-6.8361-33.002-.92884-4.8368-2.4692-14.322-3.2452-19.991-.68557-5.0083-.77707-6.9534-.74159-15.791.04316-10.803.41822-16.162 1.5026-21.503 1.4593-5.9026 3.3494-11.077 6.3247-15.852z"/>
     <path style="fill:currentColor" d="m94.499 885.78c-.10214-.0109-.13691 0-.0907.0409.16033.13489 1.329 1.0675 2.5976 2.0723 6.7003 5.307 11.273 14.568 12.658 25.638.52519 4.1949.24765 14.361-.5059 18.523-2.4775 13.684-9.7807 32.345-20.944 53.519l-3.0559 5.7971c2.8082.76579 5.7915 1.727 8.9926 2.8441 11.562-11.691 18.349-19.678 24.129-28.394 7.8992-11.913 11.132-20.234 12.24-31.518.98442-10.02-1.5579-20.876-6.7799-28.959-.2758-.4269-.57803-.86856-.89617-1.3166-3.247-6.13-9.752-12.053-21.264-16.131-2.3687-.86369-6.3657-2.0433-7.0802-2.1166z"/>
     <path style="fill:currentColor" d="m32.52 892.22c-.20090-.13016-1.4606.81389-3.9132 2.7457-11.486 9.0476-17.632 24.186-16.078 39.61.79699 7.9138 2.4066 13.505 5.9184 20.562 5.8577 11.77 14.749 23.219 30.087 38.74.05838.059.12188.1244.18052.1838 1.3166-.5556 2.5965-1.0618 3.8429-1.5199-.66408-.32448-1.4608-1.3297-3.8116-4.4602-5.0951-6.785-8.7512-11.962-13.051-18.486-5.1379-7.7948-5.0097-7.5894-8.0586-13.054-6.2097-11.13-8.2674-17.725-8.6014-27.563-.21552-6.3494.13041-9.2733 1.775-14.987 2.1832-7.5849 3.9273-10.986 9.2693-18.07 1.7839-2.3656 2.6418-3.57 2.4409-3.7003z"/>
     <path style="fill:currentColor" d="m69.133 992.37c-6.2405.0309-12.635.76718-19.554 2.5706 4.6956 4.7759 9.935 10.258 12.05 12.625l4.1272 4.6202h11.493l3.964-4.4516c2.0962-2.3541 7.4804-7.9845 12.201-12.768-8.378-1.4975-16.207-2.6353-24.281-2.5955z"/>
     <rect style="stroke-width:0;fill:currentColor" ry="2.0328" height="27.746" width="22.766" y="1017.7" x="60.201"/>
    </g>
   </g>
  </symbol>

  <symbol id="info" viewBox="0 0 41.667 41.667">
   <g transform="translate(-37.035 -1004.6)">
    <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m76.25 1030.2a18.968 18.968 0 0 1 -23.037 13.709 18.968 18.968 0 0 1 -13.738 -23.019 18.968 18.968 0 0 1 23.001 -13.768 18.968 18.968 0 0 1 13.798 22.984"/>
    <g transform="matrix(1.1146 0 0 1.1146 -26.276 -124.92)">
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m75.491 1039.5v-8.7472"/>
     <path style="stroke-width:0;fill:currentColor" transform="scale(-1)" d="m-73.193-1024.5a2.3719 2.3719 0 0 1 -2.8807 1.7142 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
   </g>
  </symbol>

  <symbol id="warning" viewBox="0 0 48.430474 41.646302">
    <g transform="translate(-1.1273 -1010.2)">
     <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:4.151;fill:none" d="m25.343 1012.3-22.14 37.496h44.28z"/>
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:4.1512;fill:none" d="m25.54 1027.7v8.7472"/>
     <path style="stroke-width:0;fill:currentColor" d="m27.839 1042.8a2.3719 2.3719 0 0 1 -2.8807 1.7143 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
  </symbol>

  <symbol id="menu" viewBox="0 0 50 50">
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="0" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="20" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="40" x="0"/>
   </symbol>

   <symbol id="link" viewBox="0 0 50 50">
    <g transform="translate(0 -1002.4)">
     <g transform="matrix(.095670 0 0 .095670 2.3233 1004.9)">
      <g>
       <path style="stroke-width:0;fill:currentColor" d="m452.84 192.9-128.65 128.65c-35.535 35.54-93.108 35.54-128.65 0l-42.881-42.886 42.881-42.876 42.884 42.876c11.845 11.822 31.064 11.846 42.886 0l128.64-128.64c11.816-11.831 11.816-31.066 0-42.9l-42.881-42.881c-11.822-11.814-31.064-11.814-42.887 0l-45.928 45.936c-21.292-12.531-45.491-17.905-69.449-16.291l72.501-72.526c35.535-35.521 93.136-35.521 128.64 0l42.886 42.881c35.535 35.523 35.535 93.141-.001 128.66zm-254.28 168.51-45.903 45.9c-11.845 11.846-31.064 11.817-42.881 0l-42.884-42.881c-11.845-11.821-11.845-31.041 0-42.886l128.65-128.65c11.819-11.814 31.069-11.814 42.884 0l42.886 42.886 42.876-42.886-42.876-42.881c-35.54-35.521-93.113-35.521-128.65 0l-128.65 128.64c-35.538 35.545-35.538 93.146 0 128.65l42.883 42.882c35.51 35.54 93.11 35.54 128.65 0l72.496-72.499c-23.956 1.597-48.092-3.784-69.474-16.283z"/>
      </g>
     </g>
    </g>
  </symbol>

  <symbol id="doc" viewBox="0 0 35 45">
   <g transform="translate(-147.53 -539.83)">
    <path style="stroke:currentColor;stroke-width:2.4501;fill:none" d="m149.38 542.67v39.194h31.354v-39.194z"/>
    <g style="stroke-width:25" transform="matrix(.098003 0 0 .098003 133.69 525.96)">
     <path d="m220 252.36h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path style="stroke:currentColor;stroke-width:25;fill:none" d="m220 409.95h200"/>
     <path d="m220 488.74h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path d="m220 331.15h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
    </g>
   </g>
 </symbol>

 <symbol id="tick" viewBox="0 0 177.16535 177.16535">
  <g transform="translate(0 -875.2)">
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="155" width="40" y="702.99" x="556.82"/>
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="40" width="90.404" y="817.99" x="506.42"/>
  </g>
 </symbol>
</svg>

    <div class="wrapper">
      <header class="intro-and-nav" role="banner">
  <div>
    <div class="intro">
      <a
        class="logo"
        href="https://op-y.github.io"
        aria-label="Qin的自习室 home page"
      >
        
          <img 
            src="/images/logo.svg" 
            alt="Logo"
          >
        
      </a>
      <p class="library-desc">
         Qin的自习室：记录学习点点滴滴的地方。 
      </p>
    </div>
    <nav id="patterns-nav" class="patterns" role="navigation">
  <h2 class="vh">Main navigation</h2>
  <button id="menu-button" aria-expanded="false">
    <svg viewBox="0 0 50 50" aria-hidden="true" focusable="false">
      <use href="#menu"></use>
    </svg>
    Menu
  </button>
  
  <ul id="patterns-list">
  
    <li class="pattern">
      
      
      
      
      <a href="/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">Qin</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/post/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">分享文章</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/tags/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">Tags</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/about/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use href="#bookmark"></use>
        </svg>
        <span class="text">关于自习室</span>
      </a>
    </li>
  
  </ul>
</nav>
    
  </div>
</header>

      <div class="main-and-footer">
        <div>
          
  <main id="main">
    <h1>
      <svg class="bookmark-icon" aria-hidden="true" viewBox="0 0 40 50" focusable="false">
        <use href="#bookmark"></use>
      </svg>
      kubeadm实战: 搭建高可用集群
    </h1>

    <div class="date">
      
      
      <strong>Publish date: </strong>Jan 7, 2024
      
        
      
    </div>

    
      <div class="tags">
        <strong>Tags: </strong>
        <ul aria-label="tags">
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/kubernetes/">kubernetes</a>
            </li>
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use href="#tag"></use>
              </svg>
              
              <a href="/tags/kubeadm/">kubeadm</a>
            </li>
          
        </ul>
      </div>
    

    
  <nav class="toc" aria-labelledby="toc-heading">
    <strong id="toc-heading">Table of Contents</strong>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#目标">目标</a></li>
    <li><a href="#环境准备">环境准备</a>
      <ul>
        <li><a href="#安装一些必要的软件包">安装一些必要的软件包</a></li>
        <li><a href="#安装-oh-my-zsh">安装 oh-my-zsh</a></li>
        <li><a href="#配置本地mac上iterm2的rzsz">配置本地Mac上iTerm2的rzsz</a></li>
        <li><a href="#配置本地域名解析">配置本地域名解析</a></li>
        <li><a href="#其它配置">其它配置</a></li>
      </ul>
    </li>
    <li><a href="#容器运行时">容器运行时</a>
      <ul>
        <li><a href="#内核模块安装和内核参数设置">内核模块安装和内核参数设置</a></li>
        <li><a href="#安装containerd">安装containerd</a></li>
        <li><a href="#安装runc">安装runc</a></li>
        <li><a href="#安装-cni-插件">安装 CNI 插件</a></li>
        <li><a href="#配置containerd">配置containerd</a></li>
        <li><a href="#nerdctl-和-buildkit">nerdctl 和 buildkit</a></li>
      </ul>
    </li>
    <li><a href="#安装-kubeadm">安装 kubeadm</a></li>
    <li><a href="#安装etcd集群">安装etcd集群</a></li>
    <li><a href="#启动第一个控制面">启动第一个控制面</a>
      <ul>
        <li><a href="#为控制面apiserver配置一个负载均衡">为控制面apiserver配置一个负载均衡</a></li>
        <li><a href="#准备kubeadm配置文件">准备kubeadm配置文件</a></li>
        <li><a href="#初始化第一个控制面">初始化第一个控制面</a></li>
        <li><a href="#安装cni插件">安装CNI插件</a></li>
      </ul>
    </li>
    <li><a href="#启动第二个控制面">启动第二个控制面</a></li>
    <li><a href="#启动一个工作节点">启动一个工作节点</a></li>
    <li><a href="#集群效果">集群效果</a></li>
    <li><a href="#验证高可用">验证高可用</a></li>
    <li><a href="#后记">后记</a></li>
  </ul>
</nav>
  </nav>



    <h2 id="目标">目标</h2>
<p>本篇记录使用 <strong>kubeadm</strong> 完成一个高可用 Kubernetes 集群搭建。</p>
<p>参考文档</p>
<ul>
<li><a href="https://v1-28.docs.kubernetes.io/zh-cn/docs/setup/production-environment/container-runtimes/">容器运行时</a></li>
<li><a href="https://v1-28.docs.kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">安装 kubernetes</a></li>
<li><a href="https://v1-28.docs.kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/ha-topology/">高可用拓扑选项</a></li>
<li><a href="https://v1-28.docs.kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/">使用 Kubeadm 创建一个高可用 etcd 集群</a></li>
<li><a href="https://etcd.io/docs/v3.5/op-guide/configuration/">etcd 配置</a></li>
<li><a href="https://v1-28.docs.kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/high-availability/">利用 kubeadm 创建高可用集群</a></li>
<li><a href="https://github.com/flannel-io/flannel/blob/master/Documentation/configuration.md">flannel 配置</a></li>
</ul>
<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use href="#info"></use>
    </svg>
    使用的版本 Kubernetes 1.28.2
  </div>
</aside>
<h2 id="环境准备">环境准备</h2>
<p>已有集群是使用阿里云轻应用服务器作为实验环境搭建的，所以先准备一台新的集群，选用了 Ubuntu 镜像（原有节点使用的 Debian，操作验证了不同 Linux 发行版组成集群没啥问题）。</p>
<h3 id="安装一些必要的软件包">安装一些必要的软件包</h3>
<pre><code>apt-get update
apt-get install git lrzsz tmux zsh fonts-powerline

# lrzsz 用于本地终端与云主机传输小文件
# tmux 方便登录云主机操作
# zsh 替换云主机shell环境 如果喜欢bash也可以保持默认环境
# fonts-powerline 是后续使用oh-my-zsh主题需要的字体
</code></pre>
<h3 id="安装-oh-my-zsh">安装 oh-my-zsh</h3>
<p>参考官方文档 <a href="https://ohmyz.sh/#install">https://ohmyz.sh/#install</a> 过程非常简单</p>
<pre><code>sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;
</code></pre>
<p>安装完成后，可以编辑 <code>~/.zshrc</code> 配置文件更换主题，这里我个人习惯使用 <em>agnoster</em> 。</p>
<h3 id="配置本地mac上iterm2的rzsz">配置本地Mac上iTerm2的rzsz</h3>
<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use href="#info"></use>
    </svg>
    使用习惯问题，不实用rzsz工具情况下，也可不做以下配置。
  </div>
</aside>
<p>在 /usr/local/bin 下准备两个脚本文件</p>
<p>iterm2-recv-zmodem.sh（从网上抄的）</p>
<pre><code>#!/bin/bash
# Author: Matt Mastracci (matthew@mastracci.com)
# AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script
# licensed under cc-wiki with attribution required
# Remainder of script public domain

osascript -e 'tell application &quot;iTerm2&quot; to version' &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm
if [[ $NAME = &quot;iTerm&quot; ]]; then
	FILE=$(osascript -e 'tell application &quot;iTerm&quot; to activate' -e 'tell application &quot;iTerm&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;' -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;)
else
	FILE=$(osascript -e 'tell application &quot;iTerm2&quot; to activate' -e 'tell application &quot;iTerm2&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;' -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;)
fi

if [[ $FILE = &quot;&quot; ]]; then
	echo Cancelled.
	# Send ZModem cancel
	echo -e \\x18\\x18\\x18\\x18\\x18
	sleep 1
	echo
	echo \# Cancelled transfer
else
	cd &quot;$FILE&quot;
	/usr/local/bin/rz --rename --escape --binary --bufsize 4096
	sleep 1
	echo
	echo
	echo \# Sent \-\&gt; $FILE
fi
</code></pre>
<p>iterm2-send-zmodem.sh（从网上抄的）</p>
<pre><code>#!/bin/bash
# Author: Matt Mastracci (matthew@mastracci.com)
# AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script
# licensed under cc-wiki with attribution required
# Remainder of script public domain

osascript -e 'tell application &quot;iTerm2&quot; to version' &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm
if [[ $NAME = &quot;iTerm&quot; ]]; then
	FILE=$(osascript -e 'tell application &quot;iTerm&quot; to activate' -e 'tell application &quot;iTerm&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;' -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;)
else
	FILE=$(osascript -e 'tell application &quot;iTerm2&quot; to activate' -e 'tell application &quot;iTerm2&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;' -e &quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;)
fi
if [[ $FILE = &quot;&quot; ]]; then
	echo Cancelled.
	# Send ZModem cancel
	echo -e \\x18\\x18\\x18\\x18\\x18
	sleep 1
	echo
	echo \# Cancelled transfer
else
	/usr/local/bin/sz &quot;$FILE&quot; --escape --binary --bufsize 4096
	sleep 1
	echo
	echo \# Received &quot;$FILE&quot;
fi
</code></pre>
<p>在iTerm2对应的Profile上配置触发器</p>









  


<figure role="group" aria-describedby="caption-7f340982017094900984601700f0d32c">
  <a href="/kubeadm-ha-cluster/figure1-iterm2-triggers.png" class="img-link">
    <img src="/kubeadm-ha-cluster/figure1-iterm2-triggers_hua00b25efc86a2fa8f20a640634227f29_59733_1080x0_resize_box_2.png">
  </a>
  <figcaption id="caption-7f340982017094900984601700f0d32c">
    配置 iTerm2 触发器
  </figcaption>
</figure>

<table>
<thead>
<tr>
<th>Regular Expression</th>
<th>&hellip;</th>
</tr>
</thead>
<tbody>
<tr>
<td>rz waiting to receive.**B0100</td>
<td>&hellip;</td>
</tr>
<tr>
<td>**B00000000000000</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h3 id="配置本地域名解析">配置本地域名解析</h3>
<p>在所有机器（实验环境是3台）的 /etc/hosts 中增加解析条目</p>
<pre><code># 以下是新增条目IP和域名做了部分掩盖

172.xx.xx.198 blue.xxx.apps
172.xx.xx.129 red.xxx.apps
172.xx.xx.132 yellow.xxx.apps

172.xx.xx.132 apiserver.xxx.apps

</code></pre>
<p>因为操作是为了方便区分机器，在终端上给三台机器笔记了红黄蓝三种颜色，索性就用了 blue、red、yellow做了主机域名。
同时先预设了 kube-apiserver 控制面域名先解析到 yellow上。</p>
<h3 id="其它配置">其它配置</h3>
<p>为了方便机器间互相访问，可以给机器都互相添加ssh信任关系，实现免密ssh登录和scp传文件等。</p>
<h2 id="容器运行时">容器运行时</h2>
<p>Kubernetes 底层依赖符合CNI规范的容器运行时，所以在部署集群之前需要安装容器运行时，这里选择最常用的 containerd。
安装步骤可以参考前述官方文档。</p>
<h3 id="内核模块安装和内核参数设置">内核模块安装和内核参数设置</h3>
<pre><code>cat &lt;&lt;EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# 设置所需的 sysctl 参数，参数在重新启动后保持不变
cat &lt;&lt;EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# 应用 sysctl 参数而不重新启动
sysctl --system

# 通过运行以下指令确认 br_netfilter 和 overlay 模块被加载
lsmod | grep br_netfilter
lsmod | grep overlay

# 通过运行以下指令确认 net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables 和 net.ipv4.ip_forward 系统变量在你的 sysctl 配置中被设置为 1
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
</code></pre>
<h3 id="安装containerd">安装containerd</h3>
<pre><code># 参考https://github.com/containerd/containerd/blob/main/docs/getting-started.md
wget https://github.com/containerd/containerd/releases/download/v1.7.2/containerd-1.7.2-linux-amd64.tar.gz
mkdir -p /usr/local/lib/systemd/system/
tar Cxzvf /usr/local containerd-1.7.2-linux-amd64.tar.gz

# 创建 containerd 的systemd service 配置文件 /usr/local/lib/systemd/system/containerd.service
systemctl daemon-reload
systemctl enable --now containerd
</code></pre>
<p>containerd.service</p>
<pre><code>[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target local-fs.target

[Service]
ExecStartPre=-/sbin/modprobe overlay
ExecStart=/usr/local/bin/containerd

Type=notify
Delegate=yes
KillMode=process
Restart=always
RestartSec=5

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNPROC=infinity
LimitCORE=infinity

# Comment TasksMax if your systemd version does not supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
OOMScoreAdjust=-999

[Install]
WantedBy=multi-user.target
</code></pre>
<h3 id="安装runc">安装runc</h3>
<pre><code>wget https://github.com/opencontainers/runc/releases/download/v1.1.7/runc.amd64 
install -m 755 runc.amd64 /usr/local/sbin/runc

# 如果要支持 seccomp
# apt-get install libseccomp-dev
</code></pre>
<h3 id="安装-cni-插件">安装 CNI 插件</h3>
<pre><code>wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
mkdir -p /opt/cni/bin
tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.3.0.tgz
</code></pre>
<h3 id="配置containerd">配置containerd</h3>
<p>当前Linux发行版使用的是 systemd 初始化系统，配置容器运行时也使用 systemd cgroup 驱动，之后启动kubelet也保持一致。</p>
<pre><code>mkdir -p /etc/containerd
containerd config default &gt; /etc/containerd/config.toml #生成一份默认配置

# vim /etc/containerd/config.toml
# 修改 SystemdCgroup = true 
# 修改 sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.9&quot;

systemctl restart containerd
</code></pre>
<h3 id="nerdctl-和-buildkit">nerdctl 和 buildkit</h3>
<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use href="#info"></use>
    </svg>
    containerd 自身提供了一个crictl 做完客户端工具进行操作，十分不好用，可以安装nerdctl 和 buildkit 来实现近似 docker的功能。
  </div>
</aside>
<pre><code># nerdctl
wget https://github.com/containerd/nerdctl/releases/download/v1.4.0/nerdctl-1.4.0-linux-amd64.tar.gz

# .zshrc 做几个别名方便使用
# alias crictl=&quot;crictl --runtime-endpoint unix:///var/run/containerd/containerd.sock&quot;
# alias docker=&quot;nerdctl&quot;
# alias docker-compose=&quot;nerdctl compose&quot;

# buildkit
wget https://github.com/moby/buildkit/releases/download/v0.11.6/buildkit-v0.11.6.linux-amd64.tar.gz
tar Czxvf /usr/local buildkit-v0.11.6.linux-amd64.tar.gz

# 配置 /usr/local/lib/systemd/system/buildkit.service
systemctl enable --now buildkit
</code></pre>
<p>buildkitd.service</p>
<pre><code>[Unit]
Description=BuildKit
Documentation=https://github.com/moby/buildkit

[Service]
Type=notify
ExecStart=/usr/local/bin/buildkitd --oci-worker=false --containerd-worker=true

[Install]
WantedBy=multi-user.target
</code></pre>
<h2 id="安装-kubeadm">安装 kubeadm</h2>
<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use href="#info"></use>
    </svg>
    如果使用 openssl 等工具给 etcd 生成证书可以先安装etcd，然后再安装 kubeadm。
这里借用kubeadm来生成证书，所以先把 kubeadm kubelet kubectl 一起安装了。
  </div>
</aside>
<pre><code>sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl

# 使用阿里云的源 原因大家都懂
sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https
curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -
cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF

# 当前版本已经升级到了1.29，所以指定了一下版本
sudo apt-get update
sudo apt-get install kubeadm kubectl kubelet
sudo apt-mark hold kubelet kubeadm kubectl

# .zshrc 做个kubectl补全配置
# source &lt;(kubectl completion zsh)
</code></pre>
<h2 id="安装etcd集群">安装etcd集群</h2>
<p>这里参考了官方文档使用 kubeadm 来生成相关证书文件，但是不使用 kubelet 托管etcd进程，而是在机器上直接启动。</p>
<p>使用以下脚本为三台机器的kubeadm生成 kubeadm-config.yaml</p>
<pre><code># 使用你的主机 IP 更新 HOST0、HOST1 和 HOST2 的 IP 地址
# 这里做了掩码
export HOST0=172.xx.xx.132
export HOST1=172.xx.xx.129
export HOST2=172.xx.xx.198

# 使用你的主机名更新 NAME0、NAME1 和 NAME2
# 这里做了掩码
export NAME0=&quot;yelllow.xxx.apps&quot;
export NAME1=&quot;red.xxx.apps&quot;
export NAME2=&quot;blue.xxx.apps&quot;

# 创建临时目录来存储将被分发到其它主机上的文件
mkdir -p /tmp/${HOST0}/ /tmp/${HOST1}/ /tmp/${HOST2}/

HOSTS=(${HOST0} ${HOST1} ${HOST2})
NAMES=(${NAME0} ${NAME1} ${NAME2})

for i in &quot;${!HOSTS[@]}&quot;; do
HOST=${HOSTS[$i]}
NAME=${NAMES[$i]}
cat &lt;&lt; EOF &gt; /tmp/${HOST}/kubeadmcfg.yaml
---
apiVersion: &quot;kubeadm.k8s.io/v1beta3&quot;
kind: InitConfiguration
nodeRegistration:
 name: ${NAME}
localAPIEndpoint:
 advertiseAddress: ${HOST}
---
apiVersion: &quot;kubeadm.k8s.io/v1beta3&quot;
kind: ClusterConfiguration
etcd:
 local:
     serverCertSANs:
     - &quot;${HOST}&quot;
     peerCertSANs:
     - &quot;${HOST}&quot;
     extraArgs:
         initial-cluster: ${NAMES[0]}=https://${HOSTS[0]}:2380,${NAMES[1]}=https://${HOSTS[1]}:2380,${NAMES[2]}=https://${HOSTS[2]}:2380
         initial-cluster-state: new
         name: ${NAME}
         listen-peer-urls: https://${HOST}:2380
         listen-client-urls: https://${HOST}:2379
         advertise-client-urls: https://${HOST}:2379
         initial-advertise-peer-urls: https://${HOST}:2380
EOF
done
</code></pre>
<p>在yellow节点上创建ca证书</p>
<pre><code>kubeadm init phase certs etcd-ca

# 生成文件
# /etc/kubernetes/pki/etcd/ca.crt
# /etc/kubernetes/pki/etcd/ca.key
</code></pre>
<p>为成员节点创建证书</p>
<pre><code># 使用你的主机 IP 更新 HOST0、HOST1 和 HOST2 的 IP 地址
# 这里做了掩码
export HOST0=172.xx.xx.132
export HOST1=172.xx.xx.129
export HOST2=172.xx.xx.198

# 使用你的主机名更新 NAME0、NAME1 和 NAME2
# 这里做了掩码
export NAME0=&quot;yelllow.xxx.apps&quot;
export NAME1=&quot;red.xxx.apps&quot;
export NAME2=&quot;blue.xxx.apps&quot;

kubeadm init phase certs etcd-server --config=/tmp/${HOST2}/kubeadmcfg.yaml
kubeadm init phase certs etcd-peer --config=/tmp/${HOST2}/kubeadmcfg.yaml
kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST2}/kubeadmcfg.yaml
kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST2}/kubeadmcfg.yaml
cp -R /etc/kubernetes/pki /tmp/${HOST2}/
# 清理不可重复使用的证书
find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete

kubeadm init phase certs etcd-server --config=/tmp/${HOST1}/kubeadmcfg.yaml
kubeadm init phase certs etcd-peer --config=/tmp/${HOST1}/kubeadmcfg.yaml
kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST1}/kubeadmcfg.yaml
kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST1}/kubeadmcfg.yaml
cp -R /etc/kubernetes/pki /tmp/${HOST1}/
find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete

kubeadm init phase certs etcd-server --config=/tmp/${HOST0}/kubeadmcfg.yaml
kubeadm init phase certs etcd-peer --config=/tmp/${HOST0}/kubeadmcfg.yaml
kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST0}/kubeadmcfg.yaml
kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST0}/kubeadmcfg.yaml
# 不需要移动 certs 因为它们是给 HOST0 使用的

# 清理不应从此主机复制的证书
find /tmp/${HOST2} -name ca.key -type f -delete
find /tmp/${HOST1} -name ca.key -type f -delete
</code></pre>
<p>复制证书和kubeadm配置到目标机器</p>
<pre><code>HOST=${HOST1}
scp -r /tmp/${HOST}/* root@${HOST}:
ssh root@${HOST}
mv pki /etc/kubernetes/

HOST=${HOST2}
scp -r /tmp/${HOST}/* root@${HOST}:
ssh root@${HOST}
mv pki /etc/kubernetes/
</code></pre>
<p>操作完成后可以登录所有机器检查证书和配置文件是否正确。</p>
<p>然后在三台机器上下载etcd的二进制包，按照集群模式启动。以下是三台机器上启动etcd的脚本。</p>
<pre><code>#!/bin/bash

nohup /home/etcd/etcd \
--advertise-client-urls=https://172.xx.xx.132:2379 \
--cert-file=/etc/kubernetes/pki/etcd/server.crt \
--client-cert-auth=true \
--data-dir=/var/lib/etcd \
--experimental-initial-corrupt-check=true \
--experimental-watch-progress-notify-interval=5s \
--initial-advertise-peer-urls=https://172.xx.xx.132:2380 \
--initial-cluster=yellow.xxx.apps=https://172.xx.xx.132:2380,red.xxx.apps=https://172.xxx.xxx.129:2380,blue.xxx.apps=https://172.xx.xx.198:2380 \
--key-file=/etc/kubernetes/pki/etcd/server.key \
--listen-client-urls=https://172.xx.xx.132:2379 \
--listen-metrics-urls=http://127.0.0.1:2381 \
--listen-peer-urls=https://172.xx.xx.132:2380 \
--name=yellow.xxx.apps \
--peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt \
--peer-client-cert-auth=true \
--peer-key-file=/etc/kubernetes/pki/etcd/peer.key \
--peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt \
--snapshot-count=10000 \
--trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt \
--initial-cluster k8s \
--initial-cluster-state new --initial-cluster-token k8s \
1&gt;start.log 2&gt;start.err &amp;


# 这个是yellow节点的
# red 和 blue 节点对应修改IP地址和域名即可
</code></pre>
<p>etcd 集群启动成功后，可以使用etcdctl客户端工具查看集群状态。</p>
<pre><code>ETCDCTL_API=3 /home/etcd/etcdctl --cert /etc/kubernetes/pki/apiserver-etcd-client.crt --key /etc/kubernetes/pki/apiserver-etcd-client.key --cacert /etc/kubernetes/pki/etcd/ca.crt --endpoints https://yellow.xxx.apps:2379,https://red.xxx.apps:2379,https://blue.xxx.apps:2379 member list
</code></pre>









  


<figure role="group" aria-describedby="caption-14670adb703689d79bac836689b78017">
  <a href="/kubeadm-ha-cluster/figure2-etcd-cluster.png" class="img-link">
    <img src="/kubeadm-ha-cluster/figure2-etcd-cluster_hu0a53a45c98a33cb322b2ff598ce39818_34624_1080x0_resize_box_2.png">
  </a>
  <figcaption id="caption-14670adb703689d79bac836689b78017">
    etcd 集群
  </figcaption>
</figure>

<h2 id="启动第一个控制面">启动第一个控制面</h2>
<h3 id="为控制面apiserver配置一个负载均衡">为控制面apiserver配置一个负载均衡</h3>
<p>这里没有做LoadBalancer配置，如果需要可以用 Nginx、LVS 等配置，实验中直接把域名 apiserver.xxx.apps 配置到yellow节点上。</p>
<h3 id="准备kubeadm配置文件">准备kubeadm配置文件</h3>
<p>~/kubeadm-config.yaml</p>
<pre><code>---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: stable
controlPlaneEndpoint: &quot;apiserver.xxx.apps:6443&quot;
imageRepository: registry.aliyuncs.com/google_containers
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
  podSubnet: 10.74.0.0/16
etcd:
  external:
    endpoints:
      - https://172.xx.xx.132:2379
      - https://172.xx.xx.129:2379
      - https://172.xx.xx.198:2379
    caFile: /etc/kubernetes/pki/etcd/ca.crt
    certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
    keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key
</code></pre>
<p>这里要注意几个配置</p>
<ul>
<li>controlPlaneEndpoint 高可用集群必须要配置这个参数</li>
<li>imageRepository 指定了从阿里云镜像仓库下载镜像 原因都懂</li>
<li>serviceSubnet 分配service IP网段</li>
<li>podSubnet 分配节点pod IP 网段</li>
<li>etcd.external 下是外部etcd 集群的相关配置</li>
</ul>
<aside aria-label="warning" class="note warning">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 48.430474 41.646302" focusable="false">
      <use href="#warning"></use>
    </svg>
    由于 podSubnet 没有配置导致 flannel 第一次启动异常！
  </div>
</aside>
<h3 id="初始化第一个控制面">初始化第一个控制面</h3>
<pre><code>kubeadm init --config kubeadm-config.yaml --upload-certs
</code></pre>
<p>输出内容如下，IP 域名 机器名经过处理。</p>
<pre><code>I0106 12:53:52.403941   61596 version.go:256] remote version is much newer: v1.29.0; falling back to: stable-1.28
[init] Using Kubernetes version: v1.28.5
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;
[certs] Generating &quot;ca&quot; certificate and key
[certs] Generating &quot;apiserver&quot; certificate and key
[certs] apiserver serving cert is signed for DNS names [apiserver.xxx.apps yellow kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.xx.xx.132]
[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key
[certs] Generating &quot;front-proxy-ca&quot; certificate and key
[certs] Generating &quot;front-proxy-client&quot; certificate and key
[certs] External etcd mode: Skipping etcd/ca certificate authority generation
[certs] External etcd mode: Skipping etcd/server certificate generation
[certs] External etcd mode: Skipping etcd/peer certificate generation
[certs] External etcd mode: Skipping etcd/healthcheck-client certificate generation
[certs] External etcd mode: Skipping apiserver-etcd-client certificate generation
[certs] Generating &quot;sa&quot; key and public key
[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;
[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file
[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;
[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;
[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;
[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Starting the kubelet
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 7.004820 seconds
[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace
[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace
[upload-certs] Using certificate key:
&lt;key&gt;
[mark-control-plane] Marking the node yellow as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node yellow as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: &lt;token&gt;
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace
[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join apiserver.xxx.apps:6443 --token &lt;token&gt; \
	--discovery-token-ca-cert-hash sha256:&lt;hash&gt; \
	--control-plane --certificate-key &lt;key&gt;

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join apiserver.xxx.apps:6443 --token &lt;token&gt; \
	--discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</code></pre>
<h3 id="安装cni插件">安装CNI插件</h3>
<p>经过一番琢磨还是选择了熟悉的 flannel。</p>
<pre><code># 这里是把文件下载到了本地
kubectl apply -f kube-flannel.yaml
</code></pre>
<aside aria-label="warning" class="note warning">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 48.430474 41.646302" focusable="false">
      <use href="#warning"></use>
    </svg>
    <p>由于一开始 kubeadm-config.yaml 中 podSubnet 没有配置导致 flannel 一开启动异常。报错 <em>Error registering network: failed to acquire lease: node pod cidr not assigned</em> 。</p>
<p>期间以为是 flannel 启动参数没有设置 &ndash;etcd-endpoints 为外部集群端点，加上之后同时加上证书相关配置，也无法正常启动。后来搜索了一下，基本都指向是节点网段没有正常分批的问题。所以在 kubeadm-config.yaml 中加上 podSubnet 配置，去掉flannel etcd证书配置，然后启动成功了。</p>
<p>这里又引入一个问题，Kubernetes中的flannel 没有配置etcd证书，为什么能正常运行？后来经过与朋友讨论，和查证资料，发现flannel可以与kubernetes通过API交互。最终确认恐怕还需要查看flannel代码。</p>
  </div>
</aside>
<h2 id="启动第二个控制面">启动第二个控制面</h2>
<p>从第一个控制面初始化输出中cp出命令执行。</p>
<pre><code>kubeadm join apiserver.xxx.apps:6443 --token &lt;token&gt; \
        --discovery-token-ca-cert-hash sha256:&lt;hash&gt; \
        --control-plane --certificate-key &lt;key&gt;
</code></pre>
<p>输出内容如下，IP 域名 机器名经过处理。</p>
<pre><code>[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[preflight] Running pre-flight checks before initializing the new control plane instance
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[download-certs] Downloading the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace
[download-certs] Saving the certificates to the folder: &quot;/etc/kubernetes/pki&quot;
[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;
[certs] Generating &quot;front-proxy-client&quot; certificate and key
[certs] Generating &quot;apiserver&quot; certificate and key
[certs] apiserver serving cert is signed for DNS names [apiserver.xxx.apps red kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.xx.xx.129]
[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key
[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;
[certs] Using the existing &quot;sa&quot; key
[kubeconfig] Generating kubeconfig files
[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;
[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file
[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;
[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;
[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;
[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;
[check-etcd] Skipping etcd check in external mode
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
[control-plane-join] Using external etcd - no local stacked instance added
The 'update-status' phase is deprecated and will be removed in a future release. Currently it performs no operation
[mark-control-plane] Marking the node red as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node red as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]

This node has joined the cluster and a new control plane instance was created:

* Certificate signing request was sent to apiserver and approval was received.
* The Kubelet was informed of the new secure connection details.
* Control plane label and taint were applied to the new node.
* The Kubernetes control plane instances scaled up.


To start administering your cluster from this node, you need to run the following as a regular user:

	mkdir -p $HOME/.kube
	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
	sudo chown $(id -u):$(id -g) $HOME/.kube/config

Run 'kubectl get nodes' to see this node join the cluster.
</code></pre>
<h2 id="启动一个工作节点">启动一个工作节点</h2>
<pre><code>kubeadm join apiserver.xxx.apps:6443 --token &lt;token&gt; \
        --discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</code></pre>
<p>输出内容如下，IP 域名 机器名经过处理。</p>
<pre><code>[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
</code></pre>
<h2 id="集群效果">集群效果</h2>
<p>如图</p>









  


<figure role="group" aria-describedby="caption-557fac63e485489f834cbf25f6b50d66">
  <a href="/kubeadm-ha-cluster/figure3-k8s-cluster.png" class="img-link">
    <img src="/kubeadm-ha-cluster/figure3-k8s-cluster_hu605635c9056535cfe039e63d39b5b07f_30811_1080x0_resize_box_2.png">
  </a>
  <figcaption id="caption-557fac63e485489f834cbf25f6b50d66">
    两个控制面节点的kubernetes集群
  </figcaption>
</figure>

<h2 id="验证高可用">验证高可用</h2>
<p>创建一个2副本的nginx Deployment和Service</p>
<pre><code>---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-dp
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:1.14
        name: nginx
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-srv
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080
  type: NodePort
</code></pre>
<p>正常部署。</p>
<p>将yellow节点上，kube-controller-manager 静态Pod的 manifest 文件mv到其它地方，这个Pod会主动消失，根据观察，red节点上的 kube-controller-manager 正常接手了controller manager的工作。</p>
<p>此时将nginx的副本书调整为4，新增的Pod正常被创建出来。</p>









  


<figure role="group" aria-describedby="caption-e423e41a165879e2c67549596c752270">
  <a href="/kubeadm-ha-cluster/figure4-nginx-deployment.png" class="img-link">
    <img src="/kubeadm-ha-cluster/figure4-nginx-deployment_hu7f4c30ba5cdbfc275b2bbc76e03c1c67_32526_1080x0_resize_box_2.png">
  </a>
  <figcaption id="caption-e423e41a165879e2c67549596c752270">
    Nginx Deployment
  </figcaption>
</figure>

<p>至此初步验证了组件的高可用。</p>
<h2 id="后记">后记</h2>
<p>折腾kubernetes真是一件很复杂又有趣的事情。在实验环境部署这个玩具高可用集群前前后后花了几个小时。最终还是折腾出来了。过程中也暴露出一些问题。</p>
<ul>
<li>kubernetes 各个组件的参数很多，真的需要认真研究各个参数的意义和作用；</li>
<li>kubeadm 配置非常的灵活，需要花时间多做实验；</li>
<li>etcd和flannel 有些生疏，有时间多练习，看看源码；</li>
<li>kubernetes 网络是绕不过去的问题，本来打算尝试calico的，后来还是放弃了，抽时间单独学习calico、weave、canal、cilium 这些CNI网络组件的使用吧；</li>
<li>一直说网络和存储带来痛苦，实在是没办法，痛苦也要学呀&hellip;</li>
</ul>
<p>希望自己能一直保持这样的好奇心和求知欲，<em>stay foolish, stay hungry</em>，共勉！</p>

  </main>
  <div id="disqus-container">
  
</div>


          
            <footer role="contentinfo">
  <div
  
  >
    <label for="themer">
      dark theme: <input type="checkbox" id="themer" class="vh">
      
      <span aria-hidden="true"></span>
    </label>
  </div>
  
    Powered by <a href="https://gohugo.io/">Hugo</a>. Themed by <a href="https://github.com/zwbetz-gh/cupper-hugo-theme">Cupper</a>.
  
</footer>

          
        </div>
      </div>
    </div>
    

<script src="/js/dom-scripts.js"></script>  

<script src="/js/prism.js"></script>





    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css" integrity="sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js" integrity="sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

    
  

  </body>
</html>
